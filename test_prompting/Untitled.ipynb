{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189880f9-0fe3-4ef9-86a4-343bbd3e1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a947a8-5298-43a8-ae4c-caada6f41189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained BERT model\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f6d33ea-2f4c-4677-87eb-d8dc2f989841",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir ='C:/Users/34639/Desktop/postgrau/project/group_project/30_06/fairyTaleAI/Checkpoints/GoodCheckpoint.pt'\n",
    "checkpoint = torch.load('path/to/your/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0af6c45-a242-4977-b12a-f0a75fe6b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = checkpoint['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c09554c-ac8e-4db5-9f74-86fa4928f5e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertModel:\n\tMissing key(s) in state_dict: \"embeddings.word_embeddings.weight\", \"embeddings.position_embeddings.weight\", \"embeddings.token_type_embeddings.weight\", \"embeddings.LayerNorm.weight\", \"embeddings.LayerNorm.bias\", \"encoder.layer.0.attention.self.query.weight\", \"encoder.layer.0.attention.self.query.bias\", \"encoder.layer.0.attention.self.key.weight\", \"encoder.layer.0.attention.self.key.bias\", \"encoder.layer.0.attention.self.value.weight\", \"encoder.layer.0.attention.self.value.bias\", \"encoder.layer.0.attention.output.dense.weight\", \"encoder.layer.0.attention.output.dense.bias\", \"encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.layer.0.intermediate.dense.weight\", \"encoder.layer.0.intermediate.dense.bias\", \"encoder.layer.0.output.dense.weight\", \"encoder.layer.0.output.dense.bias\", \"encoder.layer.0.output.LayerNorm.weight\", \"encoder.layer.0.output.LayerNorm.bias\", \"encoder.layer.1.attention.self.query.weight\", \"encoder.layer.1.attention.self.query.bias\", \"encoder.layer.1.attention.self.key.weight\", \"encoder.layer.1.attention.self.key.bias\", \"encoder.layer.1.attention.self.value.weight\", \"encoder.layer.1.attention.self.value.bias\", \"encoder.layer.1.attention.output.dense.weight\", \"encoder.layer.1.attention.output.dense.bias\", \"encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.layer.1.intermediate.dense.weight\", \"encoder.layer.1.intermediate.dense.bias\", \"encoder.layer.1.output.dense.weight\", \"encoder.layer.1.output.dense.bias\", \"encoder.layer.1.output.LayerNorm.weight\", \"encoder.layer.1.output.LayerNorm.bias\", \"encoder.layer.2.attention.self.query.weight\", \"encoder.layer.2.attention.self.query.bias\", \"encoder.layer.2.attention.self.key.weight\", \"encoder.layer.2.attention.self.key.bias\", \"encoder.layer.2.attention.self.value.weight\", \"encoder.layer.2.attention.self.value.bias\", \"encoder.layer.2.attention.output.dense.weight\", \"encoder.layer.2.attention.output.dense.bias\", \"encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.layer.2.intermediate.dense.weight\", \"encoder.layer.2.intermediate.dense.bias\", \"encoder.layer.2.output.dense.weight\", \"encoder.layer.2.output.dense.bias\", \"encoder.layer.2.output.LayerNorm.weight\", \"encoder.layer.2.output.LayerNorm.bias\", \"encoder.layer.3.attention.self.query.weight\", \"encoder.layer.3.attention.self.query.bias\", \"encoder.layer.3.attention.self.key.weight\", \"encoder.layer.3.attention.self.key.bias\", \"encoder.layer.3.attention.self.value.weight\", \"encoder.layer.3.attention.self.value.bias\", \"encoder.layer.3.attention.output.dense.weight\", \"encoder.layer.3.attention.output.dense.bias\", \"encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.layer.3.intermediate.dense.weight\", \"encoder.layer.3.intermediate.dense.bias\", \"encoder.layer.3.output.dense.weight\", \"encoder.layer.3.output.dense.bias\", \"encoder.layer.3.output.LayerNorm.weight\", \"encoder.layer.3.output.LayerNorm.bias\", \"encoder.layer.4.attention.self.query.weight\", \"encoder.layer.4.attention.self.query.bias\", \"encoder.layer.4.attention.self.key.weight\", \"encoder.layer.4.attention.self.key.bias\", \"encoder.layer.4.attention.self.value.weight\", \"encoder.layer.4.attention.self.value.bias\", \"encoder.layer.4.attention.output.dense.weight\", \"encoder.layer.4.attention.output.dense.bias\", \"encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.layer.4.intermediate.dense.weight\", \"encoder.layer.4.intermediate.dense.bias\", \"encoder.layer.4.output.dense.weight\", \"encoder.layer.4.output.dense.bias\", \"encoder.layer.4.output.LayerNorm.weight\", \"encoder.layer.4.output.LayerNorm.bias\", \"encoder.layer.5.attention.self.query.weight\", \"encoder.layer.5.attention.self.query.bias\", \"encoder.layer.5.attention.self.key.weight\", \"encoder.layer.5.attention.self.key.bias\", \"encoder.layer.5.attention.self.value.weight\", \"encoder.layer.5.attention.self.value.bias\", \"encoder.layer.5.attention.output.dense.weight\", \"encoder.layer.5.attention.output.dense.bias\", \"encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.layer.5.intermediate.dense.weight\", \"encoder.layer.5.intermediate.dense.bias\", \"encoder.layer.5.output.dense.weight\", \"encoder.layer.5.output.dense.bias\", \"encoder.layer.5.output.LayerNorm.weight\", \"encoder.layer.5.output.LayerNorm.bias\", \"encoder.layer.6.attention.self.query.weight\", \"encoder.layer.6.attention.self.query.bias\", \"encoder.layer.6.attention.self.key.weight\", \"encoder.layer.6.attention.self.key.bias\", \"encoder.layer.6.attention.self.value.weight\", \"encoder.layer.6.attention.self.value.bias\", \"encoder.layer.6.attention.output.dense.weight\", \"encoder.layer.6.attention.output.dense.bias\", \"encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.layer.6.intermediate.dense.weight\", \"encoder.layer.6.intermediate.dense.bias\", \"encoder.layer.6.output.dense.weight\", \"encoder.layer.6.output.dense.bias\", \"encoder.layer.6.output.LayerNorm.weight\", \"encoder.layer.6.output.LayerNorm.bias\", \"encoder.layer.7.attention.self.query.weight\", \"encoder.layer.7.attention.self.query.bias\", \"encoder.layer.7.attention.self.key.weight\", \"encoder.layer.7.attention.self.key.bias\", \"encoder.layer.7.attention.self.value.weight\", \"encoder.layer.7.attention.self.value.bias\", \"encoder.layer.7.attention.output.dense.weight\", \"encoder.layer.7.attention.output.dense.bias\", \"encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.layer.7.intermediate.dense.weight\", \"encoder.layer.7.intermediate.dense.bias\", \"encoder.layer.7.output.dense.weight\", \"encoder.layer.7.output.dense.bias\", \"encoder.layer.7.output.LayerNorm.weight\", \"encoder.layer.7.output.LayerNorm.bias\", \"encoder.layer.8.attention.self.query.weight\", \"encoder.layer.8.attention.self.query.bias\", \"encoder.layer.8.attention.self.key.weight\", \"encoder.layer.8.attention.self.key.bias\", \"encoder.layer.8.attention.self.value.weight\", \"encoder.layer.8.attention.self.value.bias\", \"encoder.layer.8.attention.output.dense.weight\", \"encoder.layer.8.attention.output.dense.bias\", \"encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.layer.8.intermediate.dense.weight\", \"encoder.layer.8.intermediate.dense.bias\", \"encoder.layer.8.output.dense.weight\", \"encoder.layer.8.output.dense.bias\", \"encoder.layer.8.output.LayerNorm.weight\", \"encoder.layer.8.output.LayerNorm.bias\", \"encoder.layer.9.attention.self.query.weight\", \"encoder.layer.9.attention.self.query.bias\", \"encoder.layer.9.attention.self.key.weight\", \"encoder.layer.9.attention.self.key.bias\", \"encoder.layer.9.attention.self.value.weight\", \"encoder.layer.9.attention.self.value.bias\", \"encoder.layer.9.attention.output.dense.weight\", \"encoder.layer.9.attention.output.dense.bias\", \"encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.layer.9.intermediate.dense.weight\", \"encoder.layer.9.intermediate.dense.bias\", \"encoder.layer.9.output.dense.weight\", \"encoder.layer.9.output.dense.bias\", \"encoder.layer.9.output.LayerNorm.weight\", \"encoder.layer.9.output.LayerNorm.bias\", \"encoder.layer.10.attention.self.query.weight\", \"encoder.layer.10.attention.self.query.bias\", \"encoder.layer.10.attention.self.key.weight\", \"encoder.layer.10.attention.self.key.bias\", \"encoder.layer.10.attention.self.value.weight\", \"encoder.layer.10.attention.self.value.bias\", \"encoder.layer.10.attention.output.dense.weight\", \"encoder.layer.10.attention.output.dense.bias\", \"encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.layer.10.intermediate.dense.weight\", \"encoder.layer.10.intermediate.dense.bias\", \"encoder.layer.10.output.dense.weight\", \"encoder.layer.10.output.dense.bias\", \"encoder.layer.10.output.LayerNorm.weight\", \"encoder.layer.10.output.LayerNorm.bias\", \"encoder.layer.11.attention.self.query.weight\", \"encoder.layer.11.attention.self.query.bias\", \"encoder.layer.11.attention.self.key.weight\", \"encoder.layer.11.attention.self.key.bias\", \"encoder.layer.11.attention.self.value.weight\", \"encoder.layer.11.attention.self.value.bias\", \"encoder.layer.11.attention.output.dense.weight\", \"encoder.layer.11.attention.output.dense.bias\", \"encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.layer.11.intermediate.dense.weight\", \"encoder.layer.11.intermediate.dense.bias\", \"encoder.layer.11.output.dense.weight\", \"encoder.layer.11.output.dense.bias\", \"encoder.layer.11.output.LayerNorm.weight\", \"encoder.layer.11.output.LayerNorm.bias\", \"pooler.dense.weight\", \"pooler.dense.bias\". \n\tUnexpected key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.transformer.layer.0.attention.q_lin.weight\", \"bert.transformer.layer.0.attention.q_lin.bias\", \"bert.transformer.layer.0.attention.k_lin.weight\", \"bert.transformer.layer.0.attention.k_lin.bias\", \"bert.transformer.layer.0.attention.v_lin.weight\", \"bert.transformer.layer.0.attention.v_lin.bias\", \"bert.transformer.layer.0.attention.out_lin.weight\", \"bert.transformer.layer.0.attention.out_lin.bias\", \"bert.transformer.layer.0.sa_layer_norm.weight\", \"bert.transformer.layer.0.sa_layer_norm.bias\", \"bert.transformer.layer.0.ffn.lin1.weight\", \"bert.transformer.layer.0.ffn.lin1.bias\", \"bert.transformer.layer.0.ffn.lin2.weight\", \"bert.transformer.layer.0.ffn.lin2.bias\", \"bert.transformer.layer.0.output_layer_norm.weight\", \"bert.transformer.layer.0.output_layer_norm.bias\", \"bert.transformer.layer.1.attention.q_lin.weight\", \"bert.transformer.layer.1.attention.q_lin.bias\", \"bert.transformer.layer.1.attention.k_lin.weight\", \"bert.transformer.layer.1.attention.k_lin.bias\", \"bert.transformer.layer.1.attention.v_lin.weight\", \"bert.transformer.layer.1.attention.v_lin.bias\", \"bert.transformer.layer.1.attention.out_lin.weight\", \"bert.transformer.layer.1.attention.out_lin.bias\", \"bert.transformer.layer.1.sa_layer_norm.weight\", \"bert.transformer.layer.1.sa_layer_norm.bias\", \"bert.transformer.layer.1.ffn.lin1.weight\", \"bert.transformer.layer.1.ffn.lin1.bias\", \"bert.transformer.layer.1.ffn.lin2.weight\", \"bert.transformer.layer.1.ffn.lin2.bias\", \"bert.transformer.layer.1.output_layer_norm.weight\", \"bert.transformer.layer.1.output_layer_norm.bias\", \"bert.transformer.layer.2.attention.q_lin.weight\", \"bert.transformer.layer.2.attention.q_lin.bias\", \"bert.transformer.layer.2.attention.k_lin.weight\", \"bert.transformer.layer.2.attention.k_lin.bias\", \"bert.transformer.layer.2.attention.v_lin.weight\", \"bert.transformer.layer.2.attention.v_lin.bias\", \"bert.transformer.layer.2.attention.out_lin.weight\", \"bert.transformer.layer.2.attention.out_lin.bias\", \"bert.transformer.layer.2.sa_layer_norm.weight\", \"bert.transformer.layer.2.sa_layer_norm.bias\", \"bert.transformer.layer.2.ffn.lin1.weight\", \"bert.transformer.layer.2.ffn.lin1.bias\", \"bert.transformer.layer.2.ffn.lin2.weight\", \"bert.transformer.layer.2.ffn.lin2.bias\", \"bert.transformer.layer.2.output_layer_norm.weight\", \"bert.transformer.layer.2.output_layer_norm.bias\", \"bert.transformer.layer.3.attention.q_lin.weight\", \"bert.transformer.layer.3.attention.q_lin.bias\", \"bert.transformer.layer.3.attention.k_lin.weight\", \"bert.transformer.layer.3.attention.k_lin.bias\", \"bert.transformer.layer.3.attention.v_lin.weight\", \"bert.transformer.layer.3.attention.v_lin.bias\", \"bert.transformer.layer.3.attention.out_lin.weight\", \"bert.transformer.layer.3.attention.out_lin.bias\", \"bert.transformer.layer.3.sa_layer_norm.weight\", \"bert.transformer.layer.3.sa_layer_norm.bias\", \"bert.transformer.layer.3.ffn.lin1.weight\", \"bert.transformer.layer.3.ffn.lin1.bias\", \"bert.transformer.layer.3.ffn.lin2.weight\", \"bert.transformer.layer.3.ffn.lin2.bias\", \"bert.transformer.layer.3.output_layer_norm.weight\", \"bert.transformer.layer.3.output_layer_norm.bias\", \"bert.transformer.layer.4.attention.q_lin.weight\", \"bert.transformer.layer.4.attention.q_lin.bias\", \"bert.transformer.layer.4.attention.k_lin.weight\", \"bert.transformer.layer.4.attention.k_lin.bias\", \"bert.transformer.layer.4.attention.v_lin.weight\", \"bert.transformer.layer.4.attention.v_lin.bias\", \"bert.transformer.layer.4.attention.out_lin.weight\", \"bert.transformer.layer.4.attention.out_lin.bias\", \"bert.transformer.layer.4.sa_layer_norm.weight\", \"bert.transformer.layer.4.sa_layer_norm.bias\", \"bert.transformer.layer.4.ffn.lin1.weight\", \"bert.transformer.layer.4.ffn.lin1.bias\", \"bert.transformer.layer.4.ffn.lin2.weight\", \"bert.transformer.layer.4.ffn.lin2.bias\", \"bert.transformer.layer.4.output_layer_norm.weight\", \"bert.transformer.layer.4.output_layer_norm.bias\", \"bert.transformer.layer.5.attention.q_lin.weight\", \"bert.transformer.layer.5.attention.q_lin.bias\", \"bert.transformer.layer.5.attention.k_lin.weight\", \"bert.transformer.layer.5.attention.k_lin.bias\", \"bert.transformer.layer.5.attention.v_lin.weight\", \"bert.transformer.layer.5.attention.v_lin.bias\", \"bert.transformer.layer.5.attention.out_lin.weight\", \"bert.transformer.layer.5.attention.out_lin.bias\", \"bert.transformer.layer.5.sa_layer_norm.weight\", \"bert.transformer.layer.5.sa_layer_norm.bias\", \"bert.transformer.layer.5.ffn.lin1.weight\", \"bert.transformer.layer.5.ffn.lin1.bias\", \"bert.transformer.layer.5.ffn.lin2.weight\", \"bert.transformer.layer.5.ffn.lin2.bias\", \"bert.transformer.layer.5.output_layer_norm.weight\", \"bert.transformer.layer.5.output_layer_norm.bias\", \"next_sentence.0.weight\", \"next_sentence.0.bias\", \"next_sentence.1.weight\", \"next_sentence.1.bias\", \"mask_lm.0.weight\", \"mask_lm.0.bias\", \"mask_lm.1.weight\", \"mask_lm.1.bias\", \"mask_lm.2.weight\", \"mask_lm.2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertModel:\n\tMissing key(s) in state_dict: \"embeddings.word_embeddings.weight\", \"embeddings.position_embeddings.weight\", \"embeddings.token_type_embeddings.weight\", \"embeddings.LayerNorm.weight\", \"embeddings.LayerNorm.bias\", \"encoder.layer.0.attention.self.query.weight\", \"encoder.layer.0.attention.self.query.bias\", \"encoder.layer.0.attention.self.key.weight\", \"encoder.layer.0.attention.self.key.bias\", \"encoder.layer.0.attention.self.value.weight\", \"encoder.layer.0.attention.self.value.bias\", \"encoder.layer.0.attention.output.dense.weight\", \"encoder.layer.0.attention.output.dense.bias\", \"encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.layer.0.intermediate.dense.weight\", \"encoder.layer.0.intermediate.dense.bias\", \"encoder.layer.0.output.dense.weight\", \"encoder.layer.0.output.dense.bias\", \"encoder.layer.0.output.LayerNorm.weight\", \"encoder.layer.0.output.LayerNorm.bias\", \"encoder.layer.1.attention.self.query.weight\", \"encoder.layer.1.attention.self.query.bias\", \"encoder.layer.1.attention.self.key.weight\", \"encoder.layer.1.attention.self.key.bias\", \"encoder.layer.1.attention.self.value.weight\", \"encoder.layer.1.attention.self.value.bias\", \"encoder.layer.1.attention.output.dense.weight\", \"encoder.layer.1.attention.output.dense.bias\", \"encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.layer.1.intermediate.dense.weight\", \"encoder.layer.1.intermediate.dense.bias\", \"encoder.layer.1.output.dense.weight\", \"encoder.layer.1.output.dense.bias\", \"encoder.layer.1.output.LayerNorm.weight\", \"encoder.layer.1.output.LayerNorm.bias\", \"encoder.layer.2.attention.self.query.weight\", \"encoder.layer.2.attention.self.query.bias\", \"encoder.layer.2.attention.self.key.weight\", \"encoder.layer.2.attention.self.key.bias\", \"encoder.layer.2.attention.self.value.weight\", \"encoder.layer.2.attention.self.value.bias\", \"encoder.layer.2.attention.output.dense.weight\", \"encoder.layer.2.attention.output.dense.bias\", \"encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.layer.2.intermediate.dense.weight\", \"encoder.layer.2.intermediate.dense.bias\", \"encoder.layer.2.output.dense.weight\", \"encoder.layer.2.output.dense.bias\", \"encoder.layer.2.output.LayerNorm.weight\", \"encoder.layer.2.output.LayerNorm.bias\", \"encoder.layer.3.attention.self.query.weight\", \"encoder.layer.3.attention.self.query.bias\", \"encoder.layer.3.attention.self.key.weight\", \"encoder.layer.3.attention.self.key.bias\", \"encoder.layer.3.attention.self.value.weight\", \"encoder.layer.3.attention.self.value.bias\", \"encoder.layer.3.attention.output.dense.weight\", \"encoder.layer.3.attention.output.dense.bias\", \"encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.layer.3.intermediate.dense.weight\", \"encoder.layer.3.intermediate.dense.bias\", \"encoder.layer.3.output.dense.weight\", \"encoder.layer.3.output.dense.bias\", \"encoder.layer.3.output.LayerNorm.weight\", \"encoder.layer.3.output.LayerNorm.bias\", \"encoder.layer.4.attention.self.query.weight\", \"encoder.layer.4.attention.self.query.bias\", \"encoder.layer.4.attention.self.key.weight\", \"encoder.layer.4.attention.self.key.bias\", \"encoder.layer.4.attention.self.value.weight\", \"encoder.layer.4.attention.self.value.bias\", \"encoder.layer.4.attention.output.dense.weight\", \"encoder.layer.4.attention.output.dense.bias\", \"encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.layer.4.intermediate.dense.weight\", \"encoder.layer.4.intermediate.dense.bias\", \"encoder.layer.4.output.dense.weight\", \"encoder.layer.4.output.dense.bias\", \"encoder.layer.4.output.LayerNorm.weight\", \"encoder.layer.4.output.LayerNorm.bias\", \"encoder.layer.5.attention.self.query.weight\", \"encoder.layer.5.attention.self.query.bias\", \"encoder.layer.5.attention.self.key.weight\", \"encoder.layer.5.attention.self.key.bias\", \"encoder.layer.5.attention.self.value.weight\", \"encoder.layer.5.attention.self.value.bias\", \"encoder.layer.5.attention.output.dense.weight\", \"encoder.layer.5.attention.output.dense.bias\", \"encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.layer.5.intermediate.dense.weight\", \"encoder.layer.5.intermediate.dense.bias\", \"encoder.layer.5.output.dense.weight\", \"encoder.layer.5.output.dense.bias\", \"encoder.layer.5.output.LayerNorm.weight\", \"encoder.layer.5.output.LayerNorm.bias\", \"encoder.layer.6.attention.self.query.weight\", \"encoder.layer.6.attention.self.query.bias\", \"encoder.layer.6.attention.self.key.weight\", \"encoder.layer.6.attention.self.key.bias\", \"encoder.layer.6.attention.self.value.weight\", \"encoder.layer.6.attention.self.value.bias\", \"encoder.layer.6.attention.output.dense.weight\", \"encoder.layer.6.attention.output.dense.bias\", \"encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.layer.6.intermediate.dense.weight\", \"encoder.layer.6.intermediate.dense.bias\", \"encoder.layer.6.output.dense.weight\", \"encoder.layer.6.output.dense.bias\", \"encoder.layer.6.output.LayerNorm.weight\", \"encoder.layer.6.output.LayerNorm.bias\", \"encoder.layer.7.attention.self.query.weight\", \"encoder.layer.7.attention.self.query.bias\", \"encoder.layer.7.attention.self.key.weight\", \"encoder.layer.7.attention.self.key.bias\", \"encoder.layer.7.attention.self.value.weight\", \"encoder.layer.7.attention.self.value.bias\", \"encoder.layer.7.attention.output.dense.weight\", \"encoder.layer.7.attention.output.dense.bias\", \"encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.layer.7.intermediate.dense.weight\", \"encoder.layer.7.intermediate.dense.bias\", \"encoder.layer.7.output.dense.weight\", \"encoder.layer.7.output.dense.bias\", \"encoder.layer.7.output.LayerNorm.weight\", \"encoder.layer.7.output.LayerNorm.bias\", \"encoder.layer.8.attention.self.query.weight\", \"encoder.layer.8.attention.self.query.bias\", \"encoder.layer.8.attention.self.key.weight\", \"encoder.layer.8.attention.self.key.bias\", \"encoder.layer.8.attention.self.value.weight\", \"encoder.layer.8.attention.self.value.bias\", \"encoder.layer.8.attention.output.dense.weight\", \"encoder.layer.8.attention.output.dense.bias\", \"encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.layer.8.intermediate.dense.weight\", \"encoder.layer.8.intermediate.dense.bias\", \"encoder.layer.8.output.dense.weight\", \"encoder.layer.8.output.dense.bias\", \"encoder.layer.8.output.LayerNorm.weight\", \"encoder.layer.8.output.LayerNorm.bias\", \"encoder.layer.9.attention.self.query.weight\", \"encoder.layer.9.attention.self.query.bias\", \"encoder.layer.9.attention.self.key.weight\", \"encoder.layer.9.attention.self.key.bias\", \"encoder.layer.9.attention.self.value.weight\", \"encoder.layer.9.attention.self.value.bias\", \"encoder.layer.9.attention.output.dense.weight\", \"encoder.layer.9.attention.output.dense.bias\", \"encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.layer.9.intermediate.dense.weight\", \"encoder.layer.9.intermediate.dense.bias\", \"encoder.layer.9.output.dense.weight\", \"encoder.layer.9.output.dense.bias\", \"encoder.layer.9.output.LayerNorm.weight\", \"encoder.layer.9.output.LayerNorm.bias\", \"encoder.layer.10.attention.self.query.weight\", \"encoder.layer.10.attention.self.query.bias\", \"encoder.layer.10.attention.self.key.weight\", \"encoder.layer.10.attention.self.key.bias\", \"encoder.layer.10.attention.self.value.weight\", \"encoder.layer.10.attention.self.value.bias\", \"encoder.layer.10.attention.output.dense.weight\", \"encoder.layer.10.attention.output.dense.bias\", \"encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.layer.10.intermediate.dense.weight\", \"encoder.layer.10.intermediate.dense.bias\", \"encoder.layer.10.output.dense.weight\", \"encoder.layer.10.output.dense.bias\", \"encoder.layer.10.output.LayerNorm.weight\", \"encoder.layer.10.output.LayerNorm.bias\", \"encoder.layer.11.attention.self.query.weight\", \"encoder.layer.11.attention.self.query.bias\", \"encoder.layer.11.attention.self.key.weight\", \"encoder.layer.11.attention.self.key.bias\", \"encoder.layer.11.attention.self.value.weight\", \"encoder.layer.11.attention.self.value.bias\", \"encoder.layer.11.attention.output.dense.weight\", \"encoder.layer.11.attention.output.dense.bias\", \"encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.layer.11.intermediate.dense.weight\", \"encoder.layer.11.intermediate.dense.bias\", \"encoder.layer.11.output.dense.weight\", \"encoder.layer.11.output.dense.bias\", \"encoder.layer.11.output.LayerNorm.weight\", \"encoder.layer.11.output.LayerNorm.bias\", \"pooler.dense.weight\", \"pooler.dense.bias\". \n\tUnexpected key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.transformer.layer.0.attention.q_lin.weight\", \"bert.transformer.layer.0.attention.q_lin.bias\", \"bert.transformer.layer.0.attention.k_lin.weight\", \"bert.transformer.layer.0.attention.k_lin.bias\", \"bert.transformer.layer.0.attention.v_lin.weight\", \"bert.transformer.layer.0.attention.v_lin.bias\", \"bert.transformer.layer.0.attention.out_lin.weight\", \"bert.transformer.layer.0.attention.out_lin.bias\", \"bert.transformer.layer.0.sa_layer_norm.weight\", \"bert.transformer.layer.0.sa_layer_norm.bias\", \"bert.transformer.layer.0.ffn.lin1.weight\", \"bert.transformer.layer.0.ffn.lin1.bias\", \"bert.transformer.layer.0.ffn.lin2.weight\", \"bert.transformer.layer.0.ffn.lin2.bias\", \"bert.transformer.layer.0.output_layer_norm.weight\", \"bert.transformer.layer.0.output_layer_norm.bias\", \"bert.transformer.layer.1.attention.q_lin.weight\", \"bert.transformer.layer.1.attention.q_lin.bias\", \"bert.transformer.layer.1.attention.k_lin.weight\", \"bert.transformer.layer.1.attention.k_lin.bias\", \"bert.transformer.layer.1.attention.v_lin.weight\", \"bert.transformer.layer.1.attention.v_lin.bias\", \"bert.transformer.layer.1.attention.out_lin.weight\", \"bert.transformer.layer.1.attention.out_lin.bias\", \"bert.transformer.layer.1.sa_layer_norm.weight\", \"bert.transformer.layer.1.sa_layer_norm.bias\", \"bert.transformer.layer.1.ffn.lin1.weight\", \"bert.transformer.layer.1.ffn.lin1.bias\", \"bert.transformer.layer.1.ffn.lin2.weight\", \"bert.transformer.layer.1.ffn.lin2.bias\", \"bert.transformer.layer.1.output_layer_norm.weight\", \"bert.transformer.layer.1.output_layer_norm.bias\", \"bert.transformer.layer.2.attention.q_lin.weight\", \"bert.transformer.layer.2.attention.q_lin.bias\", \"bert.transformer.layer.2.attention.k_lin.weight\", \"bert.transformer.layer.2.attention.k_lin.bias\", \"bert.transformer.layer.2.attention.v_lin.weight\", \"bert.transformer.layer.2.attention.v_lin.bias\", \"bert.transformer.layer.2.attention.out_lin.weight\", \"bert.transformer.layer.2.attention.out_lin.bias\", \"bert.transformer.layer.2.sa_layer_norm.weight\", \"bert.transformer.layer.2.sa_layer_norm.bias\", \"bert.transformer.layer.2.ffn.lin1.weight\", \"bert.transformer.layer.2.ffn.lin1.bias\", \"bert.transformer.layer.2.ffn.lin2.weight\", \"bert.transformer.layer.2.ffn.lin2.bias\", \"bert.transformer.layer.2.output_layer_norm.weight\", \"bert.transformer.layer.2.output_layer_norm.bias\", \"bert.transformer.layer.3.attention.q_lin.weight\", \"bert.transformer.layer.3.attention.q_lin.bias\", \"bert.transformer.layer.3.attention.k_lin.weight\", \"bert.transformer.layer.3.attention.k_lin.bias\", \"bert.transformer.layer.3.attention.v_lin.weight\", \"bert.transformer.layer.3.attention.v_lin.bias\", \"bert.transformer.layer.3.attention.out_lin.weight\", \"bert.transformer.layer.3.attention.out_lin.bias\", \"bert.transformer.layer.3.sa_layer_norm.weight\", \"bert.transformer.layer.3.sa_layer_norm.bias\", \"bert.transformer.layer.3.ffn.lin1.weight\", \"bert.transformer.layer.3.ffn.lin1.bias\", \"bert.transformer.layer.3.ffn.lin2.weight\", \"bert.transformer.layer.3.ffn.lin2.bias\", \"bert.transformer.layer.3.output_layer_norm.weight\", \"bert.transformer.layer.3.output_layer_norm.bias\", \"bert.transformer.layer.4.attention.q_lin.weight\", \"bert.transformer.layer.4.attention.q_lin.bias\", \"bert.transformer.layer.4.attention.k_lin.weight\", \"bert.transformer.layer.4.attention.k_lin.bias\", \"bert.transformer.layer.4.attention.v_lin.weight\", \"bert.transformer.layer.4.attention.v_lin.bias\", \"bert.transformer.layer.4.attention.out_lin.weight\", \"bert.transformer.layer.4.attention.out_lin.bias\", \"bert.transformer.layer.4.sa_layer_norm.weight\", \"bert.transformer.layer.4.sa_layer_norm.bias\", \"bert.transformer.layer.4.ffn.lin1.weight\", \"bert.transformer.layer.4.ffn.lin1.bias\", \"bert.transformer.layer.4.ffn.lin2.weight\", \"bert.transformer.layer.4.ffn.lin2.bias\", \"bert.transformer.layer.4.output_layer_norm.weight\", \"bert.transformer.layer.4.output_layer_norm.bias\", \"bert.transformer.layer.5.attention.q_lin.weight\", \"bert.transformer.layer.5.attention.q_lin.bias\", \"bert.transformer.layer.5.attention.k_lin.weight\", \"bert.transformer.layer.5.attention.k_lin.bias\", \"bert.transformer.layer.5.attention.v_lin.weight\", \"bert.transformer.layer.5.attention.v_lin.bias\", \"bert.transformer.layer.5.attention.out_lin.weight\", \"bert.transformer.layer.5.attention.out_lin.bias\", \"bert.transformer.layer.5.sa_layer_norm.weight\", \"bert.transformer.layer.5.sa_layer_norm.bias\", \"bert.transformer.layer.5.ffn.lin1.weight\", \"bert.transformer.layer.5.ffn.lin1.bias\", \"bert.transformer.layer.5.ffn.lin2.weight\", \"bert.transformer.layer.5.ffn.lin2.bias\", \"bert.transformer.layer.5.output_layer_norm.weight\", \"bert.transformer.layer.5.output_layer_norm.bias\", \"next_sentence.0.weight\", \"next_sentence.0.bias\", \"next_sentence.1.weight\", \"next_sentence.1.bias\", \"mask_lm.0.weight\", \"mask_lm.0.bias\", \"mask_lm.1.weight\", \"mask_lm.1.bias\", \"mask_lm.2.weight\", \"mask_lm.2.bias\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00627ff6-70fa-493e-827c-87295bb18fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['bert.embedding.token_embeddings.weight', 'bert.embedding.segment_embeddings.weight', 'bert.encoder_blocks.0.layernorm.weight', 'bert.encoder_blocks.0.layernorm.bias', 'bert.encoder_blocks.0.self_multihead.query.weight', 'bert.encoder_blocks.0.self_multihead.query.bias', 'bert.encoder_blocks.0.self_multihead.key.weight', 'bert.encoder_blocks.0.self_multihead.key.bias', 'bert.encoder_blocks.0.self_multihead.value.weight', 'bert.encoder_blocks.0.self_multihead.value.bias', 'bert.encoder_blocks.0.self_multihead.output_linear.weight', 'bert.encoder_blocks.0.self_multihead.output_linear.bias', 'bert.encoder_blocks.0.feed_forward.fc1.weight', 'bert.encoder_blocks.0.feed_forward.fc1.bias', 'bert.encoder_blocks.0.feed_forward.fc2.weight', 'bert.encoder_blocks.0.feed_forward.fc2.bias', 'bert.encoder_blocks.1.layernorm.weight', 'bert.encoder_blocks.1.layernorm.bias', 'bert.encoder_blocks.1.self_multihead.query.weight', 'bert.encoder_blocks.1.self_multihead.query.bias', 'bert.encoder_blocks.1.self_multihead.key.weight', 'bert.encoder_blocks.1.self_multihead.key.bias', 'bert.encoder_blocks.1.self_multihead.value.weight', 'bert.encoder_blocks.1.self_multihead.value.bias', 'bert.encoder_blocks.1.self_multihead.output_linear.weight', 'bert.encoder_blocks.1.self_multihead.output_linear.bias', 'bert.encoder_blocks.1.feed_forward.fc1.weight', 'bert.encoder_blocks.1.feed_forward.fc1.bias', 'bert.encoder_blocks.1.feed_forward.fc2.weight', 'bert.encoder_blocks.1.feed_forward.fc2.bias', 'bert.encoder_blocks.2.layernorm.weight', 'bert.encoder_blocks.2.layernorm.bias', 'bert.encoder_blocks.2.self_multihead.query.weight', 'bert.encoder_blocks.2.self_multihead.query.bias', 'bert.encoder_blocks.2.self_multihead.key.weight', 'bert.encoder_blocks.2.self_multihead.key.bias', 'bert.encoder_blocks.2.self_multihead.value.weight', 'bert.encoder_blocks.2.self_multihead.value.bias', 'bert.encoder_blocks.2.self_multihead.output_linear.weight', 'bert.encoder_blocks.2.self_multihead.output_linear.bias', 'bert.encoder_blocks.2.feed_forward.fc1.weight', 'bert.encoder_blocks.2.feed_forward.fc1.bias', 'bert.encoder_blocks.2.feed_forward.fc2.weight', 'bert.encoder_blocks.2.feed_forward.fc2.bias', 'bert.encoder_blocks.3.layernorm.weight', 'bert.encoder_blocks.3.layernorm.bias', 'bert.encoder_blocks.3.self_multihead.query.weight', 'bert.encoder_blocks.3.self_multihead.query.bias', 'bert.encoder_blocks.3.self_multihead.key.weight', 'bert.encoder_blocks.3.self_multihead.key.bias', 'bert.encoder_blocks.3.self_multihead.value.weight', 'bert.encoder_blocks.3.self_multihead.value.bias', 'bert.encoder_blocks.3.self_multihead.output_linear.weight', 'bert.encoder_blocks.3.self_multihead.output_linear.bias', 'bert.encoder_blocks.3.feed_forward.fc1.weight', 'bert.encoder_blocks.3.feed_forward.fc1.bias', 'bert.encoder_blocks.3.feed_forward.fc2.weight', 'bert.encoder_blocks.3.feed_forward.fc2.bias', 'next_sentence.linear.weight', 'next_sentence.linear.bias', 'mask_lm.linear.weight', 'mask_lm.linear.bias'])\n"
     ]
    }
   ],
   "source": [
    "model_state_dict = checkpoint['model_state_dict']\n",
    "print(model_state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6c4d64-fc1a-48c2-96f2-dd4026b81d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any prefixes in the keys if necessary\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Example to remove 'model.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in model_state_dict.items():\n",
    "    name = k.replace('model.', '')  # Adjust this line as necessary\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9afe6e1-c56b-4daf-a760-8444d9d16c81",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertModel:\n\tMissing key(s) in state_dict: \"embeddings.word_embeddings.weight\", \"embeddings.position_embeddings.weight\", \"embeddings.token_type_embeddings.weight\", \"embeddings.LayerNorm.weight\", \"embeddings.LayerNorm.bias\", \"encoder.layer.0.attention.self.query.weight\", \"encoder.layer.0.attention.self.query.bias\", \"encoder.layer.0.attention.self.key.weight\", \"encoder.layer.0.attention.self.key.bias\", \"encoder.layer.0.attention.self.value.weight\", \"encoder.layer.0.attention.self.value.bias\", \"encoder.layer.0.attention.output.dense.weight\", \"encoder.layer.0.attention.output.dense.bias\", \"encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.layer.0.intermediate.dense.weight\", \"encoder.layer.0.intermediate.dense.bias\", \"encoder.layer.0.output.dense.weight\", \"encoder.layer.0.output.dense.bias\", \"encoder.layer.0.output.LayerNorm.weight\", \"encoder.layer.0.output.LayerNorm.bias\", \"encoder.layer.1.attention.self.query.weight\", \"encoder.layer.1.attention.self.query.bias\", \"encoder.layer.1.attention.self.key.weight\", \"encoder.layer.1.attention.self.key.bias\", \"encoder.layer.1.attention.self.value.weight\", \"encoder.layer.1.attention.self.value.bias\", \"encoder.layer.1.attention.output.dense.weight\", \"encoder.layer.1.attention.output.dense.bias\", \"encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.layer.1.intermediate.dense.weight\", \"encoder.layer.1.intermediate.dense.bias\", \"encoder.layer.1.output.dense.weight\", \"encoder.layer.1.output.dense.bias\", \"encoder.layer.1.output.LayerNorm.weight\", \"encoder.layer.1.output.LayerNorm.bias\", \"encoder.layer.2.attention.self.query.weight\", \"encoder.layer.2.attention.self.query.bias\", \"encoder.layer.2.attention.self.key.weight\", \"encoder.layer.2.attention.self.key.bias\", \"encoder.layer.2.attention.self.value.weight\", \"encoder.layer.2.attention.self.value.bias\", \"encoder.layer.2.attention.output.dense.weight\", \"encoder.layer.2.attention.output.dense.bias\", \"encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.layer.2.intermediate.dense.weight\", \"encoder.layer.2.intermediate.dense.bias\", \"encoder.layer.2.output.dense.weight\", \"encoder.layer.2.output.dense.bias\", \"encoder.layer.2.output.LayerNorm.weight\", \"encoder.layer.2.output.LayerNorm.bias\", \"encoder.layer.3.attention.self.query.weight\", \"encoder.layer.3.attention.self.query.bias\", \"encoder.layer.3.attention.self.key.weight\", \"encoder.layer.3.attention.self.key.bias\", \"encoder.layer.3.attention.self.value.weight\", \"encoder.layer.3.attention.self.value.bias\", \"encoder.layer.3.attention.output.dense.weight\", \"encoder.layer.3.attention.output.dense.bias\", \"encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.layer.3.intermediate.dense.weight\", \"encoder.layer.3.intermediate.dense.bias\", \"encoder.layer.3.output.dense.weight\", \"encoder.layer.3.output.dense.bias\", \"encoder.layer.3.output.LayerNorm.weight\", \"encoder.layer.3.output.LayerNorm.bias\", \"encoder.layer.4.attention.self.query.weight\", \"encoder.layer.4.attention.self.query.bias\", \"encoder.layer.4.attention.self.key.weight\", \"encoder.layer.4.attention.self.key.bias\", \"encoder.layer.4.attention.self.value.weight\", \"encoder.layer.4.attention.self.value.bias\", \"encoder.layer.4.attention.output.dense.weight\", \"encoder.layer.4.attention.output.dense.bias\", \"encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.layer.4.intermediate.dense.weight\", \"encoder.layer.4.intermediate.dense.bias\", \"encoder.layer.4.output.dense.weight\", \"encoder.layer.4.output.dense.bias\", \"encoder.layer.4.output.LayerNorm.weight\", \"encoder.layer.4.output.LayerNorm.bias\", \"encoder.layer.5.attention.self.query.weight\", \"encoder.layer.5.attention.self.query.bias\", \"encoder.layer.5.attention.self.key.weight\", \"encoder.layer.5.attention.self.key.bias\", \"encoder.layer.5.attention.self.value.weight\", \"encoder.layer.5.attention.self.value.bias\", \"encoder.layer.5.attention.output.dense.weight\", \"encoder.layer.5.attention.output.dense.bias\", \"encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.layer.5.intermediate.dense.weight\", \"encoder.layer.5.intermediate.dense.bias\", \"encoder.layer.5.output.dense.weight\", \"encoder.layer.5.output.dense.bias\", \"encoder.layer.5.output.LayerNorm.weight\", \"encoder.layer.5.output.LayerNorm.bias\", \"encoder.layer.6.attention.self.query.weight\", \"encoder.layer.6.attention.self.query.bias\", \"encoder.layer.6.attention.self.key.weight\", \"encoder.layer.6.attention.self.key.bias\", \"encoder.layer.6.attention.self.value.weight\", \"encoder.layer.6.attention.self.value.bias\", \"encoder.layer.6.attention.output.dense.weight\", \"encoder.layer.6.attention.output.dense.bias\", \"encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.layer.6.intermediate.dense.weight\", \"encoder.layer.6.intermediate.dense.bias\", \"encoder.layer.6.output.dense.weight\", \"encoder.layer.6.output.dense.bias\", \"encoder.layer.6.output.LayerNorm.weight\", \"encoder.layer.6.output.LayerNorm.bias\", \"encoder.layer.7.attention.self.query.weight\", \"encoder.layer.7.attention.self.query.bias\", \"encoder.layer.7.attention.self.key.weight\", \"encoder.layer.7.attention.self.key.bias\", \"encoder.layer.7.attention.self.value.weight\", \"encoder.layer.7.attention.self.value.bias\", \"encoder.layer.7.attention.output.dense.weight\", \"encoder.layer.7.attention.output.dense.bias\", \"encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.layer.7.intermediate.dense.weight\", \"encoder.layer.7.intermediate.dense.bias\", \"encoder.layer.7.output.dense.weight\", \"encoder.layer.7.output.dense.bias\", \"encoder.layer.7.output.LayerNorm.weight\", \"encoder.layer.7.output.LayerNorm.bias\", \"encoder.layer.8.attention.self.query.weight\", \"encoder.layer.8.attention.self.query.bias\", \"encoder.layer.8.attention.self.key.weight\", \"encoder.layer.8.attention.self.key.bias\", \"encoder.layer.8.attention.self.value.weight\", \"encoder.layer.8.attention.self.value.bias\", \"encoder.layer.8.attention.output.dense.weight\", \"encoder.layer.8.attention.output.dense.bias\", \"encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.layer.8.intermediate.dense.weight\", \"encoder.layer.8.intermediate.dense.bias\", \"encoder.layer.8.output.dense.weight\", \"encoder.layer.8.output.dense.bias\", \"encoder.layer.8.output.LayerNorm.weight\", \"encoder.layer.8.output.LayerNorm.bias\", \"encoder.layer.9.attention.self.query.weight\", \"encoder.layer.9.attention.self.query.bias\", \"encoder.layer.9.attention.self.key.weight\", \"encoder.layer.9.attention.self.key.bias\", \"encoder.layer.9.attention.self.value.weight\", \"encoder.layer.9.attention.self.value.bias\", \"encoder.layer.9.attention.output.dense.weight\", \"encoder.layer.9.attention.output.dense.bias\", \"encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.layer.9.intermediate.dense.weight\", \"encoder.layer.9.intermediate.dense.bias\", \"encoder.layer.9.output.dense.weight\", \"encoder.layer.9.output.dense.bias\", \"encoder.layer.9.output.LayerNorm.weight\", \"encoder.layer.9.output.LayerNorm.bias\", \"encoder.layer.10.attention.self.query.weight\", \"encoder.layer.10.attention.self.query.bias\", \"encoder.layer.10.attention.self.key.weight\", \"encoder.layer.10.attention.self.key.bias\", \"encoder.layer.10.attention.self.value.weight\", \"encoder.layer.10.attention.self.value.bias\", \"encoder.layer.10.attention.output.dense.weight\", \"encoder.layer.10.attention.output.dense.bias\", \"encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.layer.10.intermediate.dense.weight\", \"encoder.layer.10.intermediate.dense.bias\", \"encoder.layer.10.output.dense.weight\", \"encoder.layer.10.output.dense.bias\", \"encoder.layer.10.output.LayerNorm.weight\", \"encoder.layer.10.output.LayerNorm.bias\", \"encoder.layer.11.attention.self.query.weight\", \"encoder.layer.11.attention.self.query.bias\", \"encoder.layer.11.attention.self.key.weight\", \"encoder.layer.11.attention.self.key.bias\", \"encoder.layer.11.attention.self.value.weight\", \"encoder.layer.11.attention.self.value.bias\", \"encoder.layer.11.attention.output.dense.weight\", \"encoder.layer.11.attention.output.dense.bias\", \"encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.layer.11.intermediate.dense.weight\", \"encoder.layer.11.intermediate.dense.bias\", \"encoder.layer.11.output.dense.weight\", \"encoder.layer.11.output.dense.bias\", \"encoder.layer.11.output.LayerNorm.weight\", \"encoder.layer.11.output.LayerNorm.bias\", \"pooler.dense.weight\", \"pooler.dense.bias\". \n\tUnexpected key(s) in state_dict: \"bert.embedding.token_embeddings.weight\", \"bert.embedding.segment_embeddings.weight\", \"bert.encoder_blocks.0.layernorm.weight\", \"bert.encoder_blocks.0.layernorm.bias\", \"bert.encoder_blocks.0.self_multihead.query.weight\", \"bert.encoder_blocks.0.self_multihead.query.bias\", \"bert.encoder_blocks.0.self_multihead.key.weight\", \"bert.encoder_blocks.0.self_multihead.key.bias\", \"bert.encoder_blocks.0.self_multihead.value.weight\", \"bert.encoder_blocks.0.self_multihead.value.bias\", \"bert.encoder_blocks.0.self_multihead.output_linear.weight\", \"bert.encoder_blocks.0.self_multihead.output_linear.bias\", \"bert.encoder_blocks.0.feed_forward.fc1.weight\", \"bert.encoder_blocks.0.feed_forward.fc1.bias\", \"bert.encoder_blocks.0.feed_forward.fc2.weight\", \"bert.encoder_blocks.0.feed_forward.fc2.bias\", \"bert.encoder_blocks.1.layernorm.weight\", \"bert.encoder_blocks.1.layernorm.bias\", \"bert.encoder_blocks.1.self_multihead.query.weight\", \"bert.encoder_blocks.1.self_multihead.query.bias\", \"bert.encoder_blocks.1.self_multihead.key.weight\", \"bert.encoder_blocks.1.self_multihead.key.bias\", \"bert.encoder_blocks.1.self_multihead.value.weight\", \"bert.encoder_blocks.1.self_multihead.value.bias\", \"bert.encoder_blocks.1.self_multihead.output_linear.weight\", \"bert.encoder_blocks.1.self_multihead.output_linear.bias\", \"bert.encoder_blocks.1.feed_forward.fc1.weight\", \"bert.encoder_blocks.1.feed_forward.fc1.bias\", \"bert.encoder_blocks.1.feed_forward.fc2.weight\", \"bert.encoder_blocks.1.feed_forward.fc2.bias\", \"bert.encoder_blocks.2.layernorm.weight\", \"bert.encoder_blocks.2.layernorm.bias\", \"bert.encoder_blocks.2.self_multihead.query.weight\", \"bert.encoder_blocks.2.self_multihead.query.bias\", \"bert.encoder_blocks.2.self_multihead.key.weight\", \"bert.encoder_blocks.2.self_multihead.key.bias\", \"bert.encoder_blocks.2.self_multihead.value.weight\", \"bert.encoder_blocks.2.self_multihead.value.bias\", \"bert.encoder_blocks.2.self_multihead.output_linear.weight\", \"bert.encoder_blocks.2.self_multihead.output_linear.bias\", \"bert.encoder_blocks.2.feed_forward.fc1.weight\", \"bert.encoder_blocks.2.feed_forward.fc1.bias\", \"bert.encoder_blocks.2.feed_forward.fc2.weight\", \"bert.encoder_blocks.2.feed_forward.fc2.bias\", \"bert.encoder_blocks.3.layernorm.weight\", \"bert.encoder_blocks.3.layernorm.bias\", \"bert.encoder_blocks.3.self_multihead.query.weight\", \"bert.encoder_blocks.3.self_multihead.query.bias\", \"bert.encoder_blocks.3.self_multihead.key.weight\", \"bert.encoder_blocks.3.self_multihead.key.bias\", \"bert.encoder_blocks.3.self_multihead.value.weight\", \"bert.encoder_blocks.3.self_multihead.value.bias\", \"bert.encoder_blocks.3.self_multihead.output_linear.weight\", \"bert.encoder_blocks.3.self_multihead.output_linear.bias\", \"bert.encoder_blocks.3.feed_forward.fc1.weight\", \"bert.encoder_blocks.3.feed_forward.fc1.bias\", \"bert.encoder_blocks.3.feed_forward.fc2.weight\", \"bert.encoder_blocks.3.feed_forward.fc2.bias\", \"next_sentence.linear.weight\", \"next_sentence.linear.bias\", \"mask_lm.linear.weight\", \"mask_lm.linear.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the adjusted state dictionary\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(new_state_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertModel:\n\tMissing key(s) in state_dict: \"embeddings.word_embeddings.weight\", \"embeddings.position_embeddings.weight\", \"embeddings.token_type_embeddings.weight\", \"embeddings.LayerNorm.weight\", \"embeddings.LayerNorm.bias\", \"encoder.layer.0.attention.self.query.weight\", \"encoder.layer.0.attention.self.query.bias\", \"encoder.layer.0.attention.self.key.weight\", \"encoder.layer.0.attention.self.key.bias\", \"encoder.layer.0.attention.self.value.weight\", \"encoder.layer.0.attention.self.value.bias\", \"encoder.layer.0.attention.output.dense.weight\", \"encoder.layer.0.attention.output.dense.bias\", \"encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.layer.0.intermediate.dense.weight\", \"encoder.layer.0.intermediate.dense.bias\", \"encoder.layer.0.output.dense.weight\", \"encoder.layer.0.output.dense.bias\", \"encoder.layer.0.output.LayerNorm.weight\", \"encoder.layer.0.output.LayerNorm.bias\", \"encoder.layer.1.attention.self.query.weight\", \"encoder.layer.1.attention.self.query.bias\", \"encoder.layer.1.attention.self.key.weight\", \"encoder.layer.1.attention.self.key.bias\", \"encoder.layer.1.attention.self.value.weight\", \"encoder.layer.1.attention.self.value.bias\", \"encoder.layer.1.attention.output.dense.weight\", \"encoder.layer.1.attention.output.dense.bias\", \"encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.layer.1.intermediate.dense.weight\", \"encoder.layer.1.intermediate.dense.bias\", \"encoder.layer.1.output.dense.weight\", \"encoder.layer.1.output.dense.bias\", \"encoder.layer.1.output.LayerNorm.weight\", \"encoder.layer.1.output.LayerNorm.bias\", \"encoder.layer.2.attention.self.query.weight\", \"encoder.layer.2.attention.self.query.bias\", \"encoder.layer.2.attention.self.key.weight\", \"encoder.layer.2.attention.self.key.bias\", \"encoder.layer.2.attention.self.value.weight\", \"encoder.layer.2.attention.self.value.bias\", \"encoder.layer.2.attention.output.dense.weight\", \"encoder.layer.2.attention.output.dense.bias\", \"encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.layer.2.intermediate.dense.weight\", \"encoder.layer.2.intermediate.dense.bias\", \"encoder.layer.2.output.dense.weight\", \"encoder.layer.2.output.dense.bias\", \"encoder.layer.2.output.LayerNorm.weight\", \"encoder.layer.2.output.LayerNorm.bias\", \"encoder.layer.3.attention.self.query.weight\", \"encoder.layer.3.attention.self.query.bias\", \"encoder.layer.3.attention.self.key.weight\", \"encoder.layer.3.attention.self.key.bias\", \"encoder.layer.3.attention.self.value.weight\", \"encoder.layer.3.attention.self.value.bias\", \"encoder.layer.3.attention.output.dense.weight\", \"encoder.layer.3.attention.output.dense.bias\", \"encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.layer.3.intermediate.dense.weight\", \"encoder.layer.3.intermediate.dense.bias\", \"encoder.layer.3.output.dense.weight\", \"encoder.layer.3.output.dense.bias\", \"encoder.layer.3.output.LayerNorm.weight\", \"encoder.layer.3.output.LayerNorm.bias\", \"encoder.layer.4.attention.self.query.weight\", \"encoder.layer.4.attention.self.query.bias\", \"encoder.layer.4.attention.self.key.weight\", \"encoder.layer.4.attention.self.key.bias\", \"encoder.layer.4.attention.self.value.weight\", \"encoder.layer.4.attention.self.value.bias\", \"encoder.layer.4.attention.output.dense.weight\", \"encoder.layer.4.attention.output.dense.bias\", \"encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.layer.4.intermediate.dense.weight\", \"encoder.layer.4.intermediate.dense.bias\", \"encoder.layer.4.output.dense.weight\", \"encoder.layer.4.output.dense.bias\", \"encoder.layer.4.output.LayerNorm.weight\", \"encoder.layer.4.output.LayerNorm.bias\", \"encoder.layer.5.attention.self.query.weight\", \"encoder.layer.5.attention.self.query.bias\", \"encoder.layer.5.attention.self.key.weight\", \"encoder.layer.5.attention.self.key.bias\", \"encoder.layer.5.attention.self.value.weight\", \"encoder.layer.5.attention.self.value.bias\", \"encoder.layer.5.attention.output.dense.weight\", \"encoder.layer.5.attention.output.dense.bias\", \"encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.layer.5.intermediate.dense.weight\", \"encoder.layer.5.intermediate.dense.bias\", \"encoder.layer.5.output.dense.weight\", \"encoder.layer.5.output.dense.bias\", \"encoder.layer.5.output.LayerNorm.weight\", \"encoder.layer.5.output.LayerNorm.bias\", \"encoder.layer.6.attention.self.query.weight\", \"encoder.layer.6.attention.self.query.bias\", \"encoder.layer.6.attention.self.key.weight\", \"encoder.layer.6.attention.self.key.bias\", \"encoder.layer.6.attention.self.value.weight\", \"encoder.layer.6.attention.self.value.bias\", \"encoder.layer.6.attention.output.dense.weight\", \"encoder.layer.6.attention.output.dense.bias\", \"encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.layer.6.intermediate.dense.weight\", \"encoder.layer.6.intermediate.dense.bias\", \"encoder.layer.6.output.dense.weight\", \"encoder.layer.6.output.dense.bias\", \"encoder.layer.6.output.LayerNorm.weight\", \"encoder.layer.6.output.LayerNorm.bias\", \"encoder.layer.7.attention.self.query.weight\", \"encoder.layer.7.attention.self.query.bias\", \"encoder.layer.7.attention.self.key.weight\", \"encoder.layer.7.attention.self.key.bias\", \"encoder.layer.7.attention.self.value.weight\", \"encoder.layer.7.attention.self.value.bias\", \"encoder.layer.7.attention.output.dense.weight\", \"encoder.layer.7.attention.output.dense.bias\", \"encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.layer.7.intermediate.dense.weight\", \"encoder.layer.7.intermediate.dense.bias\", \"encoder.layer.7.output.dense.weight\", \"encoder.layer.7.output.dense.bias\", \"encoder.layer.7.output.LayerNorm.weight\", \"encoder.layer.7.output.LayerNorm.bias\", \"encoder.layer.8.attention.self.query.weight\", \"encoder.layer.8.attention.self.query.bias\", \"encoder.layer.8.attention.self.key.weight\", \"encoder.layer.8.attention.self.key.bias\", \"encoder.layer.8.attention.self.value.weight\", \"encoder.layer.8.attention.self.value.bias\", \"encoder.layer.8.attention.output.dense.weight\", \"encoder.layer.8.attention.output.dense.bias\", \"encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.layer.8.intermediate.dense.weight\", \"encoder.layer.8.intermediate.dense.bias\", \"encoder.layer.8.output.dense.weight\", \"encoder.layer.8.output.dense.bias\", \"encoder.layer.8.output.LayerNorm.weight\", \"encoder.layer.8.output.LayerNorm.bias\", \"encoder.layer.9.attention.self.query.weight\", \"encoder.layer.9.attention.self.query.bias\", \"encoder.layer.9.attention.self.key.weight\", \"encoder.layer.9.attention.self.key.bias\", \"encoder.layer.9.attention.self.value.weight\", \"encoder.layer.9.attention.self.value.bias\", \"encoder.layer.9.attention.output.dense.weight\", \"encoder.layer.9.attention.output.dense.bias\", \"encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.layer.9.intermediate.dense.weight\", \"encoder.layer.9.intermediate.dense.bias\", \"encoder.layer.9.output.dense.weight\", \"encoder.layer.9.output.dense.bias\", \"encoder.layer.9.output.LayerNorm.weight\", \"encoder.layer.9.output.LayerNorm.bias\", \"encoder.layer.10.attention.self.query.weight\", \"encoder.layer.10.attention.self.query.bias\", \"encoder.layer.10.attention.self.key.weight\", \"encoder.layer.10.attention.self.key.bias\", \"encoder.layer.10.attention.self.value.weight\", \"encoder.layer.10.attention.self.value.bias\", \"encoder.layer.10.attention.output.dense.weight\", \"encoder.layer.10.attention.output.dense.bias\", \"encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.layer.10.intermediate.dense.weight\", \"encoder.layer.10.intermediate.dense.bias\", \"encoder.layer.10.output.dense.weight\", \"encoder.layer.10.output.dense.bias\", \"encoder.layer.10.output.LayerNorm.weight\", \"encoder.layer.10.output.LayerNorm.bias\", \"encoder.layer.11.attention.self.query.weight\", \"encoder.layer.11.attention.self.query.bias\", \"encoder.layer.11.attention.self.key.weight\", \"encoder.layer.11.attention.self.key.bias\", \"encoder.layer.11.attention.self.value.weight\", \"encoder.layer.11.attention.self.value.bias\", \"encoder.layer.11.attention.output.dense.weight\", \"encoder.layer.11.attention.output.dense.bias\", \"encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.layer.11.intermediate.dense.weight\", \"encoder.layer.11.intermediate.dense.bias\", \"encoder.layer.11.output.dense.weight\", \"encoder.layer.11.output.dense.bias\", \"encoder.layer.11.output.LayerNorm.weight\", \"encoder.layer.11.output.LayerNorm.bias\", \"pooler.dense.weight\", \"pooler.dense.bias\". \n\tUnexpected key(s) in state_dict: \"bert.embedding.token_embeddings.weight\", \"bert.embedding.segment_embeddings.weight\", \"bert.encoder_blocks.0.layernorm.weight\", \"bert.encoder_blocks.0.layernorm.bias\", \"bert.encoder_blocks.0.self_multihead.query.weight\", \"bert.encoder_blocks.0.self_multihead.query.bias\", \"bert.encoder_blocks.0.self_multihead.key.weight\", \"bert.encoder_blocks.0.self_multihead.key.bias\", \"bert.encoder_blocks.0.self_multihead.value.weight\", \"bert.encoder_blocks.0.self_multihead.value.bias\", \"bert.encoder_blocks.0.self_multihead.output_linear.weight\", \"bert.encoder_blocks.0.self_multihead.output_linear.bias\", \"bert.encoder_blocks.0.feed_forward.fc1.weight\", \"bert.encoder_blocks.0.feed_forward.fc1.bias\", \"bert.encoder_blocks.0.feed_forward.fc2.weight\", \"bert.encoder_blocks.0.feed_forward.fc2.bias\", \"bert.encoder_blocks.1.layernorm.weight\", \"bert.encoder_blocks.1.layernorm.bias\", \"bert.encoder_blocks.1.self_multihead.query.weight\", \"bert.encoder_blocks.1.self_multihead.query.bias\", \"bert.encoder_blocks.1.self_multihead.key.weight\", \"bert.encoder_blocks.1.self_multihead.key.bias\", \"bert.encoder_blocks.1.self_multihead.value.weight\", \"bert.encoder_blocks.1.self_multihead.value.bias\", \"bert.encoder_blocks.1.self_multihead.output_linear.weight\", \"bert.encoder_blocks.1.self_multihead.output_linear.bias\", \"bert.encoder_blocks.1.feed_forward.fc1.weight\", \"bert.encoder_blocks.1.feed_forward.fc1.bias\", \"bert.encoder_blocks.1.feed_forward.fc2.weight\", \"bert.encoder_blocks.1.feed_forward.fc2.bias\", \"bert.encoder_blocks.2.layernorm.weight\", \"bert.encoder_blocks.2.layernorm.bias\", \"bert.encoder_blocks.2.self_multihead.query.weight\", \"bert.encoder_blocks.2.self_multihead.query.bias\", \"bert.encoder_blocks.2.self_multihead.key.weight\", \"bert.encoder_blocks.2.self_multihead.key.bias\", \"bert.encoder_blocks.2.self_multihead.value.weight\", \"bert.encoder_blocks.2.self_multihead.value.bias\", \"bert.encoder_blocks.2.self_multihead.output_linear.weight\", \"bert.encoder_blocks.2.self_multihead.output_linear.bias\", \"bert.encoder_blocks.2.feed_forward.fc1.weight\", \"bert.encoder_blocks.2.feed_forward.fc1.bias\", \"bert.encoder_blocks.2.feed_forward.fc2.weight\", \"bert.encoder_blocks.2.feed_forward.fc2.bias\", \"bert.encoder_blocks.3.layernorm.weight\", \"bert.encoder_blocks.3.layernorm.bias\", \"bert.encoder_blocks.3.self_multihead.query.weight\", \"bert.encoder_blocks.3.self_multihead.query.bias\", \"bert.encoder_blocks.3.self_multihead.key.weight\", \"bert.encoder_blocks.3.self_multihead.key.bias\", \"bert.encoder_blocks.3.self_multihead.value.weight\", \"bert.encoder_blocks.3.self_multihead.value.bias\", \"bert.encoder_blocks.3.self_multihead.output_linear.weight\", \"bert.encoder_blocks.3.self_multihead.output_linear.bias\", \"bert.encoder_blocks.3.feed_forward.fc1.weight\", \"bert.encoder_blocks.3.feed_forward.fc1.bias\", \"bert.encoder_blocks.3.feed_forward.fc2.weight\", \"bert.encoder_blocks.3.feed_forward.fc2.bias\", \"next_sentence.linear.weight\", \"next_sentence.linear.bias\", \"mask_lm.linear.weight\", \"mask_lm.linear.bias\". "
     ]
    }
   ],
   "source": [
    "# Load the adjusted state dictionary\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291756a-bbfc-4792-8f4f-f3121d5561e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
